{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Collect User Input and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Function to preprocess text using spaCy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "# Function to preprocess and vectorize user input\n",
    "def preprocess_user_input(user_input, vectorizer):\n",
    "    combined_text = ' '.join([preprocess_text(value) for value in user_input.values()])\n",
    "    processed_text = vectorizer.transform([combined_text])\n",
    "    return processed_text\n",
    "\n",
    "# Load cleaned data\n",
    "cleaned_file_path = 'cleaned_medicine_dataset.csv'\n",
    "data = pd.read_csv(cleaned_file_path, low_memory=False)\n",
    "\n",
    "# Combine relevant columns into a single 'text' column for processing\n",
    "def combine_text(row):\n",
    "    return ' '.join([\n",
    "        str(row['substitute0']),\n",
    "        str(row['substitute1']),\n",
    "        str(row['substitute2']),\n",
    "        str(row['substitute3']),\n",
    "        str(row['substitute4']),\n",
    "        str(row['sideEffect0']),\n",
    "        str(row['sideEffect1']),\n",
    "        str(row['sideEffect2']),\n",
    "        str(row['use0']),\n",
    "        str(row['use1']),\n",
    "        str(row['Chemical Class']),\n",
    "        str(row['Therapeutic Class']),\n",
    "        str(row['Action Class'])\n",
    "    ])\n",
    "\n",
    "data['combined_text'] = data.apply(combine_text, axis=1)\n",
    "\n",
    "# Preprocess the combined text in parallel\n",
    "def parallelize_dataframe(df, func):\n",
    "    num_cores = mp.cpu_count()\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "    pool = mp.Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def preprocess_texts(df):\n",
    "    df['combined_text'] = df['combined_text'].apply(preprocess_text)\n",
    "    return df\n",
    "\n",
    "data = parallelize_dataframe(data, preprocess_texts)\n",
    "\n",
    "# Use transpose explicitly if DataFrame operations involve axis swapping\n",
    "data = data.transpose().transpose()\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(data['combined_text'])\n",
    "y = data['name']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and compile model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model with reduced sample size for quick testing\n",
    "sample_size = 5000  # Reduce this for quicker runs\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=sample_size, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_sample.toarray(), y_train_sample, epochs=5, batch_size=32, validation_data=(X_test.toarray(), y_test))\n",
    "\n",
    "# Get user input\n",
    "user_input = {\n",
    "    'primary_reason': input(\"What is your primary reason for seeking medication? \"),\n",
    "    'allergies': input(\"Do you have any known allergies or sensitivities to medications? \"),\n",
    "    'current_medications': input(\"Are you currently taking any other medications (prescription, over-the-counter, supplements)? \"),\n",
    "    'adverse_reactions': input(\"Have you had any adverse reactions to medications in the past? If so, please describe. \"),\n",
    "    'chronic_conditions': input(\"Do you have any chronic medical conditions (e.g., diabetes, hypertension, asthma)? \"),\n",
    "    'symptoms': input(\"Can you describe your symptoms in detail? When did they start? \"),\n",
    "    'symptom_severity': input(\"How severe are your symptoms? Have they been getting better, worse, or staying the same? \")\n",
    "}\n",
    "\n",
    "# Preprocess and vectorize user input\n",
    "user_vector = preprocess_user_input(user_input, vectorizer)\n",
    "\n",
    "# Predict medication\n",
    "user_prediction = model.predict(user_vector.toarray())\n",
    "predicted_medicine_index = user_prediction.argmax(axis=1)\n",
    "recommended_medicine = label_encoder.inverse_transform(predicted_medicine_index)\n",
    "\n",
    "print(f\"Recommended Medicine: {recommended_medicine[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
